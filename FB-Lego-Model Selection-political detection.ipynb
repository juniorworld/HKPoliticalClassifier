{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My F-beta score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference with default F1 score:\n",
    "When deal with tricky metric like this\n",
    "<pre>\n",
    "|         |      |     True    |\n",
    "|         |      |   0  |   1  |\n",
    "|---------|------|------|------|\n",
    "| Predict |   0  |   3  |   0  |\n",
    "|         |   1  |   4  |   0  |\n",
    "</pre>\n",
    "No real positive samples makes the denominator and numeratore of F1 metric equal to 0. F1, recall, precision = 0/0.\n",
    "Default F1 test are all equal to 0. But in my opinion: F1, recall, precision score are 0, 1, 0 respectively.\n",
    "\n",
    "-------\n",
    "And this:\n",
    "          True\n",
    "           0\n",
    "Predict   0   3\n",
    "In this case, I will set all of F1, recall, precision to 1. However, the default is 0.\n",
    "\n",
    "--------\n",
    "Besides, my version could return the cross table as above.\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about Beta:\n",
    "![title](f1score.svg)\n",
    "beta < 1 lends more weight to precision, while beta > 1 favors recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Score (PredictList,TrueList,beta):\n",
    "    X=pd.concat([pd.DataFrame(PredictList),pd.DataFrame(TrueList)],axis=1, ignore_index=True)\n",
    "    X['count']=1\n",
    "    X.columns=['Predict','True','count']\n",
    "    Acc=X.pivot_table(index='Predict',columns='True',values='count',aggfunc=np.sum)\n",
    "    Acc=Acc.fillna(value=0)\n",
    "    rate,f1,recall,precision=0,0,0,0\n",
    "    b=beta**2\n",
    "    if Acc.shape==(2,2):\n",
    "        rate=rate+(float(Acc[0][0]+Acc[1][1])/Acc.sum().sum())\n",
    "        if Acc[1][1]!=0:\n",
    "            recall=float(Acc[1][1])/float(Acc[1][0]+Acc[1][1])\n",
    "            precision=float(Acc[1][1])/float(Acc[0][1]+Acc[1][1])\n",
    "            f1=(1+b) * (float(Acc[1][1])/float(Acc[0][1]+Acc[1][1])) * (float(Acc[1][1])/float(Acc[1][0]+Acc[1][1])) / ((b * float(Acc[1][1])/float(Acc[0][1]+Acc[1][1])) + (float(Acc[1][1])/float(Acc[1][0]+Acc[1][1])))\n",
    "    elif Acc.shape==(1,2):\n",
    "        if Acc.index[0]==0:\n",
    "            rate=rate+(float(Acc[0][0])/Acc.sum().sum())\n",
    "        else:\n",
    "            rate=float(Acc[0][1])/Acc.sum().sum()\n",
    "            recall=1\n",
    "            precision=float(Acc[0][1])/Acc.sum().sum()\n",
    "            f1=(1+b) * ((float(Acc[0][1])/Acc.sum().sum()) * 1) / ((b * float(Acc[0][1])/Acc.sum().sum()) + 1)\n",
    "    elif Acc.shape==(2,1):\n",
    "        if Acc.columns==1:\n",
    "            rate=float(Acc.iloc[1])/Acc.sum().sum()\n",
    "            recall=float(Acc.iloc[1])/Acc.sum().sum()\n",
    "            precision=1\n",
    "            f1=(1+b) * float(Acc.iloc[1])/Acc.sum().sum()/(float(Acc.iloc[1])/Acc.sum().sum()+ b)\n",
    "        else:\n",
    "            rate=float(Acc.iloc[0])/Acc.sum().sum()\n",
    "            recall=1\n",
    "    else: #Acc.shape=(1,1)\n",
    "        rate=1\n",
    "        recall=1\n",
    "        precision=1\n",
    "        f1=1\n",
    "    return Acc,rate,f1,recall,precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y=pd.read_csv('comm-at-least-4-Y.csv',header=0,index_col=0)\n",
    "Y=Y.sort_index(axis=0, level=None, ascending=True)\n",
    "Y=Y.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_political=Y.sum(axis=1)\n",
    "Y_political[Y_political>0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076\n"
     ]
    }
   ],
   "source": [
    "print Y_political.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_political_yes=Y[Y_political>0]\n",
    "metric_variance_political_yes=metric_variance[np.where(Y_political>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_political_yes=Y[classifiers[\"MulBayes\"][\"f\"].predict(metric_variance)>0]\n",
    "metric_variance_political_yes=metric_variance[np.where(classifiers[\"MulBayes\"][\"f\"].predict(metric_variance)>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow    722\n",
      "Blue       19\n",
      "Local      86\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print Y_political_yes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import and Transform X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likeall=pd.read_csv(\"./comm-at-least-4-engage.txt\",header=None, names=['time','pageid','uid'],sep=' ')\n",
    "likeall['count']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_metric=likeall.pivot_table(index='uid',columns='pageid',values='count',aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save metric\n",
    "new_metric.to_csv(path_or_buf='./comm-at-least-4-engage-metric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_metric=new_metric.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection (1): Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.09)\n",
    "metric_variance=selector.fit_transform(new_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2815, 970)\n",
      "(2815L, 61L)\n"
     ]
    }
   ],
   "source": [
    "print new_metric.shape\n",
    "print metric_variance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(metric_variance_political_yes, Y_political_yes['Local'], test_size=0.0)\n",
    "y_train=np.asarray(y_train,dtype=\"float64\")\n",
    "y_test=np.asarray(y_test,dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282L, 61L) (282L,) (2533L, 61L) (2533L,)\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape, y_test.shape,X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727.0"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515L, 67L)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list=np.where(y_train==0)\n",
    "len(list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del_index=np.random.choice(list[0],size=len(list[0])/2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train=np.delete(y_train,del_index, None)\n",
    "X_train=np.delete(X_train,del_index, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(709L,)\n",
      "(709L, 61L)\n"
     ]
    }
   ],
   "source": [
    "print y_train.shape\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(kind='regular',ratio=0.3)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3151L, 61L)\n",
      "727\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print len(y_train[y_train==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "#new_metric=new_metric.fillna(value=0)\n",
    "metric_pca=pca.fit_transform(X_train)\n",
    "#metric_pca=pca.fit_transform(pre_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58833931652814542"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1015L, 10L)\n"
     ]
    }
   ],
   "source": [
    "print metric_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=10, init='random',alpha=0.01,max_iter=500,tol=1e-4,random_state=0)\n",
    "model=model.fit(X_train)\n",
    "metric_nmf=model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815L, 10L)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#component-page\n",
    "model.components_.shape\n",
    "#user-component\n",
    "metric_nmf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Assign X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=new_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=metric_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=metric_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=metric_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015L, 10L)"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection (2) : Coefficient p value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many variables are significantly related to Y: 9\n",
      "[[ 0.          0.          0.          0.08084395  0.00173334  0.          0.\n",
      "   0.          0.00021892  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg=LogisticRegression()\n",
    "LogReg.fit(X_selected, Y_label)\n",
    "sse = np.sum((LogReg.predict(X_selected) - Y_label) ** 2, axis=0) / float(X_selected.shape[0] - X_selected.shape[1])\n",
    "se = np.array([\n",
    "        np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X_selected.T, X_selected))))\n",
    "    ])\n",
    "t = LogReg.coef_ / se\n",
    "p = 2 * (1 - stats.t.cdf(np.abs(t), Y_label.shape[0] - X_selected.shape[1]))\n",
    "np.set_printoptions(suppress=True)\n",
    "print 'How many variables are significantly related to Y:',len(p[p<0.05])\n",
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "selector = RFE(LogReg, 9, step=1)\n",
    "selector = selector.fit(X_selected, Y_label)\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815L, 9L)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected=X_selected[:,selector.support_]\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection (3): Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chi Square\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2(X_train, y_train)[1].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p value\n",
    "len(chi2(X_train, y_train)[1][chi2(X_train, y_train)[1]<0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SKB = SelectKBest(chi2, k=56).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=SKB.transform(X_train)\n",
    "X_test=SKB.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          accuracy    f-beta    recall  precision\n",
      "MulBayes  0.868917  0.185026  0.155255   0.251753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#cross-validation\n",
    "from sklearn.cross_validation import KFold\n",
    "k=10\n",
    "kf = KFold(len(y_train), n_folds=k,shuffle=True)\n",
    "\n",
    "classifiers = {\"MulBayes\": {\"f\": MultinomialNB()},\n",
    "               #\"RandomForest\": {\"f\": RandomForestClassifier()},\n",
    "               #\"DecisionTree\": {\"f\": DecisionTreeClassifier()},\n",
    "               #\"LogReg\": {\"f\": LogisticRegression()},\n",
    "               #\"SVR\": {\"f\":SVR(kernel='rbf', gamma=0.1)}\n",
    "              }\n",
    "\n",
    "beta=1\n",
    "for model,color in zip(classifiers.keys(),colors):\n",
    "    recall,rate,precision,f1 = 0.0,0.0,0.0,0.0\n",
    "    n=0\n",
    "    for train_index, test_index in kf:\n",
    "        # Fit\n",
    "        classifiers[model][\"f\"].fit(X_train[train_index], y_train[train_index])\n",
    "        # Predict\n",
    "        if model==\"SVR\":\n",
    "            predicts=classifiers[model][\"f\"].predict(X_train[test_index])\n",
    "            predicts[predicts<=0.5]=0\n",
    "            predicts[predicts>0.5]=1\n",
    "            Acc,rate_fold,f1_fold,recall_fold,precision_fold=Score(predicts,y_train[test_index],beta)\n",
    "        else:\n",
    "            Acc,rate_fold,f1_fold,recall_fold,precision_fold=Score(classifiers[model][\"f\"].predict(X_train[test_index]),y_train[test_index],beta)\n",
    "        rate+=rate_fold\n",
    "        f1+=f1_fold\n",
    "        recall+=recall_fold\n",
    "        precision+=precision_fold\n",
    "    rate=float(rate)/k\n",
    "    recall=float(recall)/k\n",
    "    precision=float(precision)/k\n",
    "    f1=float(f1)/k\n",
    "    classifiers[model][\"Scores\"]={\"accuracy\":rate, \"f-beta\":f1, \"recall\":recall, \"precision\":precision}\n",
    "    classifiers[model][\"predict\"] = classifiers[model][\"f\"].predict(X_train)\n",
    "    if model!=\"SVR\":\n",
    "        classifiers[model][\"predict_prob\"] = classifiers[model][\"f\"].predict_proba(X_train)\n",
    "    else:\n",
    "        classifiers[model][\"predict_prob\"] = np.asarray([[1-i,i] for i in classifiers[model][\"f\"].predict(X_train)])\n",
    "\n",
    "# Evaluate the performance\n",
    "results = pd.DataFrame(columns=classifiers[classifiers.keys()[0]][\"Scores\"].keys())\n",
    "\n",
    "for model in classifiers.keys():\n",
    "    results.loc[model] = classifiers[model][\"Scores\"].values()\n",
    "\n",
    "print results[[\"accuracy\",\"f-beta\",\"recall\",\"precision\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          accuracy    f-beta    recall  precision\n",
      "MulBayes  0.723404  0.632075  0.663366   0.603604\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "colors = [  'yellow','seagreen','cyan', 'indigo', 'blue', 'darkorange']\n",
    "lw = 2\n",
    "\n",
    "results = pd.DataFrame(columns=[\"accuracy\",\"f-beta\",\"recall\",\"precision\"])\n",
    "\n",
    "for model,color in zip(classifiers.keys(),colors):\n",
    "    if model==\"SVR\":\n",
    "        predicts=classifiers[model][\"f\"].predict(X_test)\n",
    "        predicts[predicts<=0.5]=0\n",
    "        predicts[predicts>0.5]=1\n",
    "        Acc,rate,f1,recall,precision=Score(predicts,y_test,beta)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, classifiers[model][\"f\"].predict(X_test))\n",
    "    else:\n",
    "        Acc,rate,f1,recall,precision=Score(classifiers[model][\"f\"].predict(X_test),y_test,beta)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, classifiers[model][\"f\"].predict_proba(X_test)[:,-1])\n",
    "    results.loc[model]=rate,f1,recall,precision\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=lw, color=color,label=model+'(area = %0.2f)' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k',label='Random')\n",
    "print results\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('ROC curve - Yellow')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
