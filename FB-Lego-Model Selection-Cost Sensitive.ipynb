{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y=pd.read_csv('comm-at-least-4-Y.csv',header=0,index_col=0)\n",
    "Y=Y.sort_index(axis=0, level=None, ascending=True)\n",
    "Y=Y.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import and Transform X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likeall=pd.read_csv(\"./comm-at-least-4-engage.txt\",header=None, names=['time','pageid','uid'],sep=' ')\n",
    "likeall['count']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_metric=likeall.pivot_table(index='uid',columns='pageid',values='count',aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save metric\n",
    "new_metric.to_csv(path_or_buf='./comm-at-least-4-engage-metric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_metric=new_metric.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection: Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.09)\n",
    "metric_variance=selector.fit_transform(new_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2015, 895)\n",
      "(2015L, 67L)\n"
     ]
    }
   ],
   "source": [
    "print new_metric.shape\n",
    "print metric_variance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(metric_variance, Y['Blue'], test_size=200,random_state=42)\n",
    "y_train=np.asarray(y_train,dtype=\"float64\")\n",
    "y_test=np.asarray(y_test,dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200L, 67L) (200L,) (1815L, 67L) (1815L,)\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape, y_test.shape,X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_selected=X_train\n",
    "Y_label=np.asarray(y_train, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515L, 67L)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list=np.where(Y_label==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del_index=np.random.choice(list[0],size=(1748-73), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_label=np.delete(Y_label,del_index, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_selected=np.delete(X_selected,del_index, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140L,)\n",
      "(140L, 67L)\n"
     ]
    }
   ],
   "source": [
    "print Y_label.shape\n",
    "print X_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(kind='regular',ratio=0.1)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1919L, 67L)\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print len(y_train[y_train==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "#new_metric=new_metric.fillna(value=0)\n",
    "metric_pca=pca.fit_transform(X_train)\n",
    "#metric_pca=pca.fit_transform(pre_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58833931652814542"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1015L, 10L)\n"
     ]
    }
   ],
   "source": [
    "print metric_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=10, init='random',alpha=0.01,max_iter=500,tol=1e-4,random_state=0)\n",
    "model=model.fit(X_train)\n",
    "metric_nmf=model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815L, 10L)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#component-page\n",
    "model.components_.shape\n",
    "#user-component\n",
    "metric_nmf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Assign X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=new_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=metric_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=metric_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=metric_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015L, 10L)"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My F-beta score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference with default F1 score:\n",
    "When deal with tricky metric like this\n",
    "<pre>\n",
    "|         |      |     True    |\n",
    "|         |      |   0  |   1  |\n",
    "|---------|------|------|------|\n",
    "| Predict |   0  |   3  |   0  |\n",
    "|         |   1  |   4  |   0  |\n",
    "</pre>\n",
    "No real positive samples makes the denominator and numeratore of F1 metric equal to 0. F1, recall, precision = 0/0.\n",
    "Default F1 test are all equal to 0. But in my opinion: F1, recall, precision score are 0, 1, 0 respectively.\n",
    "\n",
    "-------\n",
    "And this:\n",
    "          True\n",
    "           0\n",
    "Predict   0   3\n",
    "In this case, I will set all of F1, recall, precision to 1. However, the default is 0.\n",
    "\n",
    "--------\n",
    "Besides, my version could return the cross table as above.\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about Beta:\n",
    "![title](f1score.svg)\n",
    "beta < 1 lends more weight to precision, while beta > 1 favors recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Score (PredictList,TrueList,beta):\n",
    "    X=pd.concat([pd.DataFrame(PredictList),pd.DataFrame(TrueList)],axis=1, ignore_index=True)\n",
    "    X['count']=1\n",
    "    X.columns=['Predict','True','count']\n",
    "    Acc=X.pivot_table(index='Predict',columns='True',values='count',aggfunc=np.sum)\n",
    "    Acc=Acc.fillna(value=0)\n",
    "    rate,f1,recall,precision=0,0,0,0\n",
    "    b=beta**2\n",
    "    if Acc.shape==(2,2):\n",
    "        rate=rate+(float(Acc[0][0]+Acc[1][1])/Acc.sum().sum())\n",
    "        if Acc[1][1]!=0:\n",
    "            recall=float(Acc[1][1])/float(Acc[1][0]+Acc[1][1])\n",
    "            precision=float(Acc[1][1])/float(Acc[0][1]+Acc[1][1])\n",
    "            f1=(1+b) * (float(Acc[1][1])/float(Acc[0][1]+Acc[1][1])) * (float(Acc[1][1])/float(Acc[1][0]+Acc[1][1])) / ((b * float(Acc[1][1])/float(Acc[0][1]+Acc[1][1])) + (float(Acc[1][1])/float(Acc[1][0]+Acc[1][1])))\n",
    "    elif Acc.shape==(1,2):\n",
    "        if Acc.index[0]==0:\n",
    "            rate=rate+(float(Acc[0][0])/Acc.sum().sum())\n",
    "        else:\n",
    "            rate=float(Acc[0][1])/Acc.sum().sum()\n",
    "            recall=1\n",
    "            precision=float(Acc[0][1])/Acc.sum().sum()\n",
    "            f1=(1+b) * ((float(Acc[0][1])/Acc.sum().sum()) * 1) / ((b * float(Acc[0][1])/Acc.sum().sum()) + 1)\n",
    "    elif Acc.shape==(2,1):\n",
    "        if Acc.columns==1:\n",
    "            rate=float(Acc.iloc[1])/Acc.sum().sum()\n",
    "            recall=float(Acc.iloc[1])/Acc.sum().sum()\n",
    "            precision=1\n",
    "            f1=(1+b) * float(Acc.iloc[1])/Acc.sum().sum()/(float(Acc.iloc[1])/Acc.sum().sum()+ b)\n",
    "        else:\n",
    "            rate=float(Acc.iloc[0])/Acc.sum().sum()\n",
    "            recall=1\n",
    "    else: #Acc.shape=(1,1)\n",
    "        rate=1\n",
    "        recall=1\n",
    "        precision=1\n",
    "        f1=1\n",
    "    return Acc,rate,f1,recall,precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Correlation p value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many variables are significantly related to Y: 9\n",
      "[[ 0.          0.          0.          0.08084395  0.00173334  0.          0.\n",
      "   0.          0.00021892  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg=LogisticRegression()\n",
    "LogReg.fit(X_selected, Y_label)\n",
    "sse = np.sum((LogReg.predict(X_selected) - Y_label) ** 2, axis=0) / float(X_selected.shape[0] - X_selected.shape[1])\n",
    "se = np.array([\n",
    "        np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X_selected.T, X_selected))))\n",
    "    ])\n",
    "t = LogReg.coef_ / se\n",
    "p = 2 * (1 - stats.t.cdf(np.abs(t), Y_label.shape[0] - X_selected.shape[1]))\n",
    "np.set_printoptions(suppress=True)\n",
    "print 'How many variables are significantly related to Y:',len(p[p<0.05])\n",
    "print p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "selector = RFE(LogReg, 9, step=1)\n",
    "selector = selector.fit(X_selected, Y_label)\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815L, 9L)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected=X_selected[:,selector.support_]\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chi Square\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 1020,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p value\n",
    "len(chi2(X_selected, Y_label)[1][chi2(X_selected, Y_label)[1]<0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SKB = SelectKBest(chi2, k=46).fit(X_selected, Y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_selected=SKB.transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test=SKB.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  accuracy    f-beta    recall  precision\n",
      "LogReg            0.958718  0.015385  0.010000   0.033333\n",
      "RandomForest      0.954301  0.062626  0.054286   0.075000\n",
      "DecisionTree      0.927287  0.069098  0.066508   0.076349\n",
      "MulBayes          0.874376  0.270337  0.581934   0.179876\n",
      "LogReg-BMR        0.917904  0.298677  0.481667   0.222747\n",
      "RandomForest-BMR  0.981817  0.778637  0.875476   0.706209\n",
      "DecisionTree-BMR  0.984579  0.801067  0.831190   0.788611\n",
      "MulBayes-BMR      0.896430  0.239180  0.443095   0.167894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#cost-sensitivity\n",
    "from costcla.models import BayesMinimumRiskClassifier\n",
    "#cross-validation\n",
    "from sklearn.cross_validation import KFold\n",
    "k=10\n",
    "kf = KFold(1815, n_folds=k,shuffle=True)\n",
    "\n",
    "classifiers = {\"MulBayes\": {\"f\": MultinomialNB()},\n",
    "               \"RandomForest\": {\"f\": RandomForestClassifier()},\n",
    "               \"DecisionTree\": {\"f\": DecisionTreeClassifier()},\n",
    "               \"LogReg\": {\"f\": LogisticRegression()}}\n",
    "\n",
    "beta=1\n",
    "for model in classifiers.keys():\n",
    "    recall,rate,precision,f1 = 0.0,0.0,0.0,0.0\n",
    "    for train_index, test_index in kf:\n",
    "        # Fit\n",
    "        classifiers[model][\"f\"].fit(X_train[train_index], y_train[train_index])\n",
    "        # Predict\n",
    "        Acc,rate_fold,f1_fold,recall_fold,precision_fold=Score(classifiers[model][\"f\"].predict(X_train[test_index]),y_train[test_index],beta)\n",
    "        rate+=rate_fold\n",
    "        f1+=f1_fold\n",
    "        recall+=recall_fold\n",
    "        precision+=precision_fold\n",
    "    rate=float(rate)/k\n",
    "    recall=float(recall)/k\n",
    "    precision=float(precision)/k\n",
    "    f1=float(f1)/k\n",
    "    classifiers[model][\"Scores\"]={\"accuracy\":rate, \"f-beta\":f1, \"recall\":recall, \"precision\":precision}\n",
    "    classifiers[model][\"predict\"] = classifiers[model][\"f\"].predict(X_train)\n",
    "    classifiers[model][\"predict_prob\"] = classifiers[model][\"f\"].predict_proba(X_train)\n",
    "        \n",
    "# Evaluate the performance\n",
    "results = pd.DataFrame(columns=classifiers[classifiers.keys()[0]][\"Scores\"].keys())\n",
    "\n",
    "for model in classifiers.keys():\n",
    "    results.loc[model] = classifiers[model][\"Scores\"].values()\n",
    "\n",
    "print results[[\"accuracy\",\"f-beta\",\"recall\",\"precision\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: The \"costcla\" is not reliable. The results look weird and different with my maunual calculation. Unsure whose problem is this, mine or costcla's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#add cost-sensitivity model\n",
    "cost=1 #switch\n",
    "# cost_mat[C_FP,C_FN,C_TP,C_TN]\n",
    "FP=10\n",
    "FN=10\n",
    "cost_mat=np.zeros((len(y_train),4))\n",
    "for i in range(len(y_train)):\n",
    "    cost_mat[i]=[FP,FN*X_train[i].sum(),0.0,0.0]\n",
    "if cost==1:\n",
    "    kf = KFold(1815, n_folds=k,shuffle=True)\n",
    "    for model in classifiers.keys():\n",
    "        classifiers[model+\"-BMR\"] = {\"f\": BayesMinimumRiskClassifier()}\n",
    "        recall,rate,precision,f1 = 0.0,0.0,0.0,0.0\n",
    "        for train_index, test_index in kf:\n",
    "            #fit\n",
    "            classifiers[model+\"-BMR\"][\"f\"].fit(y_train[train_index], classifiers[model][\"predict_prob\"][train_index])\n",
    "            # Predict\n",
    "            predict = classifiers[model+\"-BMR\"][\"f\"].predict(classifiers[model][\"predict_prob\"][test_index], cost_mat[test_index])\n",
    "            Acc,rate_fold,f1_fold,recall_fold,precision_fold=Score(predict,y_train[test_index],beta)\n",
    "            ''''if model=='DecisionTree':\n",
    "                print Acc\n",
    "                print recall_fold,precision_fold\n",
    "                print '------------'''\n",
    "            rate+=rate_fold\n",
    "            f1+=f1_fold\n",
    "            recall+=recall_fold\n",
    "            precision+=precision_fold\n",
    "        rate=float(rate)/k\n",
    "        recall=float(recall)/k\n",
    "        precision=float(precision)/k\n",
    "        f1=float(f1)/k\n",
    "        classifiers[model+\"-BMR\"][\"Scores\"]={\"accuracy\":rate, \"f-beta\":f1, \"recall\":recall, \"precision\":precision}\n",
    "        results.loc[model+\"-BMR\"] = 0\n",
    "        results.loc[model+\"-BMR\"] = classifiers[model+\"-BMR\"][\"Scores\"].values()\n",
    "\n",
    "print results[[\"accuracy\",\"f-beta\",\"recall\",\"precision\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest -BMR\n",
      "True     0.0  1.0\n",
      "Predict          \n",
      "0.0      188    6\n",
      "1.0        5    1\n",
      "LogReg -BMR\n",
      "True     0.0  1.0\n",
      "Predict          \n",
      "0.0      193    7\n",
      "DecisionTree -BMR\n",
      "True     0.0  1.0\n",
      "Predict          \n",
      "0.0      185    5\n",
      "1.0        8    2\n",
      "MulBayes -BMR\n",
      "True     0.0  1.0\n",
      "Predict          \n",
      "0.0      193    7\n",
      "                  accuracy    f-beta    recall  precision\n",
      "RandomForest         0.950  0.166667  0.142857   0.200000\n",
      "RandomForest-BMR     0.945  0.153846  0.142857   0.166667\n",
      "LogReg               0.965  0.000000  0.000000   0.000000\n",
      "LogReg-BMR           0.965  0.000000  0.000000   0.000000\n",
      "DecisionTree         0.935  0.235294  0.285714   0.200000\n",
      "DecisionTree-BMR     0.935  0.235294  0.285714   0.200000\n",
      "MulBayes             0.855  0.216216  0.571429   0.133333\n",
      "MulBayes-BMR         0.965  0.000000  0.000000   0.000000\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=[\"accuracy\",\"f-beta\",\"recall\",\"precision\"])\n",
    "for model in classifiers.keys():\n",
    "    if \"BMR\" not in model:\n",
    "        Acc,rate,f1,recall,precision=Score(classifiers[model][\"f\"].predict(X_test),y_test,beta)\n",
    "        results.loc[model]=rate,f1,recall,precision\n",
    "        cost_mat=np.zeros((len(y_test),4))\n",
    "        for i in range(len(y_test)):\n",
    "            cost_mat[i]=[FP*X_test[i].sum(),FN*X_test[i].sum(),0.0,0.0]\n",
    "        predict = classifiers[model+\"-BMR\"][\"f\"].predict(classifiers[model][\"f\"].predict_proba(X_test), cost_mat)\n",
    "        Acc,rate,f1,recall,precision=Score(predict,y_test,beta)\n",
    "        print model,'-BMR'\n",
    "        print Acc\n",
    "        results.loc[model+\"-BMR\"]=rate,f1,recall,precision\n",
    "\n",
    "print results"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
