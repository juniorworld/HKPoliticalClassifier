{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My F-beta score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference with default F1 score:\n",
    "When deal with tricky metric like this\n",
    "<pre>\n",
    "|         |      |     True    |\n",
    "|         |      |   0  |   1  |\n",
    "|---------|------|------|------|\n",
    "| Predict |   0  |   3  |   0  |\n",
    "|         |   1  |   4  |   0  |\n",
    "</pre>\n",
    "No real positive samples makes the denominator and numeratore of F1 metric equal to 0. F1, recall, precision = 0/0.\n",
    "Default F1 test are all equal to 0. But in my opinion: F1, recall, precision score are 0, 1, 0 respectively.\n",
    "\n",
    "-------\n",
    "And this:\n",
    "          True\n",
    "           0\n",
    "Predict   0   3\n",
    "In this case, I will set all of F1, recall, precision to 1. However, the default is 0.\n",
    "\n",
    "--------\n",
    "Besides, my version could return the cross table as above.\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about Beta:\n",
    "![title](f1score.svg)\n",
    "beta < 1 lends more weight to precision, while beta > 1 favors recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Score (PredictList,TrueList,beta):\n",
    "    X=pd.concat([pd.DataFrame(PredictList),pd.DataFrame(TrueList)],axis=1, ignore_index=True)\n",
    "    X['count']=1\n",
    "    X.columns=['Predict','True','count']\n",
    "    Acc=X.pivot_table(index='Predict',columns='True',values='count',aggfunc=np.sum)\n",
    "    Acc=Acc.fillna(value=0)\n",
    "    rate,f1,recall,precision=0,0,0,0\n",
    "    b=beta**2\n",
    "    if Acc.shape==(2,2):\n",
    "        rate=rate+(float(Acc[0][0]+Acc[1][1])/Acc.sum().sum())\n",
    "        if Acc[1][1]!=0:\n",
    "            recall=float(Acc[1][1])/float(Acc[1][0]+Acc[1][1])\n",
    "            precision=float(Acc[1][1])/float(Acc[0][1]+Acc[1][1])\n",
    "            f1=(1+b) * (float(Acc[1][1])/float(Acc[0][1]+Acc[1][1])) * (float(Acc[1][1])/float(Acc[1][0]+Acc[1][1])) / ((b * float(Acc[1][1])/float(Acc[0][1]+Acc[1][1])) + (float(Acc[1][1])/float(Acc[1][0]+Acc[1][1])))\n",
    "    elif Acc.shape==(1,2):\n",
    "        if Acc.index[0]==0:\n",
    "            rate=rate+(float(Acc[0][0])/Acc.sum().sum())\n",
    "        else:\n",
    "            rate=float(Acc[0][1])/Acc.sum().sum()\n",
    "            recall=1\n",
    "            precision=float(Acc[0][1])/Acc.sum().sum()\n",
    "            f1=(1+b) * ((float(Acc[0][1])/Acc.sum().sum()) * 1) / ((b * float(Acc[0][1])/Acc.sum().sum()) + 1)\n",
    "    elif Acc.shape==(2,1):\n",
    "        if Acc.columns==1:\n",
    "            rate=float(Acc.iloc[1])/Acc.sum().sum()\n",
    "            recall=float(Acc.iloc[1])/Acc.sum().sum()\n",
    "            precision=1\n",
    "            f1=(1+b) * float(Acc.iloc[1])/Acc.sum().sum()/(float(Acc.iloc[1])/Acc.sum().sum()+ b)\n",
    "        else:\n",
    "            rate=float(Acc.iloc[0])/Acc.sum().sum()\n",
    "            recall=1\n",
    "    else: #Acc.shape=(1,1)\n",
    "        rate=1\n",
    "        recall=1\n",
    "        precision=1\n",
    "        f1=1\n",
    "    return Acc,rate,f1,recall,precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y=pd.read_csv('comm-at-least-4-Y.csv',header=0,index_col=0)\n",
    "Y=Y.sort_index(axis=0, level=None, ascending=True)\n",
    "Y=Y.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y=Y[Y.index.isin(new_metric.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109L"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y['Local'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2692"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histgram of Commenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#page-unique_user\n",
    "like_unique=likeall.groupby(['pageid','uid']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comm_unique=commall.groupby(['pageid','uid']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1511\n",
      "1452\n"
     ]
    }
   ],
   "source": [
    "print len(likeall.pageid.unique())\n",
    "print len(commall.pageid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a2=comm_unique.index.tolist()\n",
    "b2=[i[0] for i in a2]\n",
    "unique2,counts2=np.unique(b2, return_counts=True)\n",
    "count2=dict(zip(unique2, counts2))\n",
    "count_2=count2.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=like_unique.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replicable pageid\n",
    "b=[i[0] for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count={page: count of unique user}\n",
    "unique, counts = np.unique(b, return_counts=True)\n",
    "count=dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list of unique users number\n",
    "count_=count.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48  0  0 49 34  0 74 24 28 52 56 39 35 59 41 51 63 54 51 59 64 64 65 58 47\n",
      " 43 43 28 32 42 25 21 24 15  8 17  5  9  4  3  4  3  4  4  1  0  1  1  0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print values\n",
    "print base[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03305785123966942, 0.03305785123966942, 0.03305785123966942, 0.06680440771349862, 0.09022038567493113]\n",
      "[ 1.          1.25892541  1.58489319  1.99526231  2.51188643]\n"
     ]
    }
   ],
   "source": [
    "print cumulative[0:5]\n",
    "print base[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.871201010907891"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import math\n",
    "\n",
    "fig=plt.figure(figsize=(20,15))\n",
    "ax=fig.add_subplot(111)\n",
    "xlabs=[10**i for i in np.arange(0,7,0.1)]\n",
    "# evaluate the histogram\n",
    "values, base = np.histogram(count_, bins=xlabs)\n",
    "values2, base2 = np.histogram(count_2, bins=xlabs)\n",
    "#evaluate the cumulative\n",
    "cumulative = np.cumsum(values)\n",
    "cumulative2 = np.cumsum(values2)\n",
    "# plot the cumulative function\n",
    "cumulative=[float(i)/1511 for i in cumulative]\n",
    "cumulative2=[float(i)/1511 for i in cumulative2]\n",
    "#values=[math.log(i+1) for i in values]\n",
    "#ax.plot(base[:-1], cumulative, c='blue')\n",
    "#ax.loglog(base[:-1], cumulative, basex=10, basey=10)\n",
    "ax.plot(base[:-1], cumulative,c='blue',lw=2, label='comment')\n",
    "ax.plot(base2[:-1], cumulative2,c='green',lw=2, label='like')\n",
    "plt.legend(loc='lower right')\n",
    "ax.plot()\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.set_yscale(\"log\", nonposx='clip')\n",
    "ax.set_ylim(10**(-3),1.5)\n",
    "plt.xlabel('count of unique like/comment users')\n",
    "plt.ylabel('cummulative percent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count_of_count={unique users number: count of them}\n",
    "unique, counts = np.unique(count_, return_counts=True)\n",
    "count_of_count=dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_of_count=sorted(count_of_count.iteritems(), key=lambda d:d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import and Transform X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#commall=pd.read_csv(\"./commall.csv\",header=None, names=['time','pageid','uid'],sep=',')\n",
    "likeall=pd.read_csv(\"./like-at-least-4-engage.txt\",header=None, names=['time','pageid','uid'],sep=' ')\n",
    "likeall['count']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del likeall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commall=pd.read_csv(\"./comm-at-least-4-engage.txt\",header=None, names=['time','pageid','uid'],sep=' ')\n",
    "commall['count']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_metric=likeall.pivot_table(index='uid',columns='pageid',values='count',aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_metric2=commall.pivot_table(index='uid',columns='pageid',values='count',aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save metric\n",
    "new_metric.to_csv(path_or_buf='./comm-at-least-4-engage-metric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_metric=new_metric.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_metric2=new_metric2.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_metric_combined=pd.concat([new_metric,new_metric2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_metric_combined=new_metric_combined.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2692, 1303)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2815, 970)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metric2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection (1): Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.001)\n",
    "metric_variance=selector.fit_transform(new_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pageid=new_metric_combined.columns[selector.variances_>0.09]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2692, 1303)\n",
      "(2692L, 1145L)\n"
     ]
    }
   ],
   "source": [
    "print new_metric.shape\n",
    "print metric_variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([      7847926891,       8100113319,       8748127833,\n",
      "                 10795878252,      12840197743,      13716140500,\n",
      "                 18809502474,      27743445015,      28211179048,\n",
      "                 28297822718,\n",
      "            ...\n",
      "             522230507809373,  535289793202478,  544241848968882,\n",
      "             548856635131690,  568718043162016,  569337929781203,\n",
      "             706305859460576,  761870613900500,  834591649886233,\n",
      "            1476654739234157],\n",
      "           dtype='int64', name=u'pageid', length=489)\n"
     ]
    }
   ],
   "source": [
    "print pageid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_metric, Y, test_size=0.1)\n",
    "y_train=np.asarray(y_train,dtype=\"float64\")\n",
    "y_test=np.asarray(y_test,dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 1303) (270L, 3L) (2422, 1303) (2422L, 3L)\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape, y_test.shape,X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515L, 67L)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list=np.where(y_train==0)\n",
    "len(list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del_index=np.random.choice(list[0],size=len(list[0])/2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train=np.delete(y_train,del_index, None)\n",
    "X_train=np.delete(X_train,del_index, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(709L,)\n",
      "(709L, 61L)\n"
     ]
    }
   ],
   "source": [
    "print y_train.shape\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(kind='regular',ratio=0.3)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3151L, 61L)\n",
      "727\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print len(y_train[y_train==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "#new_metric=new_metric.fillna(value=0)\n",
    "metric_pca=pca.fit_transform(X_train)\n",
    "#metric_pca=pca.fit_transform(pre_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58833931652814542"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1015L, 10L)\n"
     ]
    }
   ],
   "source": [
    "print metric_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=10, init='random',alpha=0.01,max_iter=500,tol=1e-4,random_state=0)\n",
    "model=model.fit(X_train)\n",
    "metric_nmf=model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815L, 10L)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#component-page\n",
    "model.components_.shape\n",
    "#user-component\n",
    "metric_nmf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Assign X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=new_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=metric_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=metric_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=metric_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015L, 10L)"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection (2) : Coefficient p value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many variables are significantly related to Y: 9\n",
      "[[ 0.          0.          0.          0.08084395  0.00173334  0.          0.\n",
      "   0.          0.00021892  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg=LogisticRegression()\n",
    "LogReg.fit(X_selected, Y_label)\n",
    "sse = np.sum((LogReg.predict(X_selected) - Y_label) ** 2, axis=0) / float(X_selected.shape[0] - X_selected.shape[1])\n",
    "se = np.array([\n",
    "        np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X_selected.T, X_selected))))\n",
    "    ])\n",
    "t = LogReg.coef_ / se\n",
    "p = 2 * (1 - stats.t.cdf(np.abs(t), Y_label.shape[0] - X_selected.shape[1]))\n",
    "np.set_printoptions(suppress=True)\n",
    "print 'How many variables are significantly related to Y:',len(p[p<0.05])\n",
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "selector = RFE(LogReg, 9, step=1)\n",
    "selector = selector.fit(X_selected, Y_label)\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815L, 9L)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected=X_selected[:,selector.support_]\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection (3): Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chi Square\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2\n",
      "[ 0.032  0.052  0.857 ...,  0.207  0.786  0.083]\n",
      "p value\n",
      "[ 0.857  0.82   0.354 ...,  0.649  0.375  0.774]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3,suppress=True)\n",
    "print 'chi2'\n",
    "print chi2(metric_variance, Y[:,2])[0]\n",
    "print 'p value'\n",
    "print chi2(metric_variance, Y[:,2])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p value\n",
    "len(chi2(X_train, y_train)[1][chi2(X_train, y_train)[1]<0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SKB = SelectKBest(chi2, k=782).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=SKB.transform(X_train)\n",
    "X_test=SKB.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_metric, Y, test_size=0.2)\n",
    "y_train=np.asarray(y_train,dtype=\"float64\")\n",
    "y_test=np.asarray(y_test,dtype=\"float64\")\n",
    "X_train=np.asarray(X_train,dtype=\"float64\")\n",
    "X_test=np.asarray(X_test,dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                accuracy    f-beta    recall  precision\n",
      "Neural Network  0.941012  0.213426  0.215913   0.231429\n",
      "MulBayes        0.882961  0.304944  0.617619   0.210410\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#cross-validation\n",
    "from sklearn.cross_validation import KFold\n",
    "k=10\n",
    "kf = KFold(len(y_train), n_folds=k,shuffle=True)\n",
    "\n",
    "classifiers = {\"MulBayes\": {\"f\": MultinomialNB()},\n",
    "               #\"RandomForest\": {\"f\": RandomForestClassifier()},\n",
    "               #\"DecisionTree\": {\"f\": DecisionTreeClassifier()},\n",
    "               #\"LogReg\": {\"f\": LogisticRegression()},\n",
    "               #\"LogReg-Reg\": {\"f\": LogisticRegression(C=1.5)},\n",
    "               \"Neural Network\": {\"f\": MLPClassifier(solver='lbfgs', activation=\"logistic\",alpha=1,hidden_layer_sizes=(50,), random_state=1)},\n",
    "               #\"SVC\": {\"f\":SVC(probability=True,kernel='rbf')}\n",
    "              }\n",
    "\n",
    "beta=1\n",
    "for n in range(2,3):\n",
    "    for model in classifiers.keys():\n",
    "        recall,rate,precision,f1 = 0.0,0.0,0.0,0.0\n",
    "        for train_index, test_index in kf:\n",
    "            # Fit\n",
    "            classifiers[model][\"f\"].fit(X_train[train_index], y_train[train_index,n])\n",
    "            # Predict\n",
    "            Acc,rate_fold,f1_fold,recall_fold,precision_fold=Score(classifiers[model][\"f\"].predict(X_train[test_index]),y_train[test_index,n],beta)\n",
    "            rate+=rate_fold\n",
    "            f1+=f1_fold\n",
    "            recall+=recall_fold\n",
    "            precision+=precision_fold\n",
    "        rate=float(rate)/k\n",
    "        recall=float(recall)/k\n",
    "        precision=float(precision)/k\n",
    "        f1=float(f1)/k\n",
    "        classifiers[model][\"Scores\"]={\"accuracy\":rate, \"f-beta\":f1, \"recall\":recall, \"precision\":precision}\n",
    "        classifiers[model][\"predict\"] = classifiers[model][\"f\"].predict(X_train)\n",
    "        classifiers[model][\"predict_prob\"] = classifiers[model][\"f\"].predict_proba(X_train)\n",
    "    \n",
    "# Evaluate the performance\n",
    "results = pd.DataFrame(columns=classifiers[classifiers.keys()[0]][\"Scores\"].keys())\n",
    "\n",
    "for model in classifiers.keys():\n",
    "    results.loc[model] = classifiers[model][\"Scores\"].values()\n",
    "\n",
    "print results[[\"accuracy\",\"f-beta\",\"recall\",\"precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter=(classifiers[\"Neural Network\"][\"f\"].coefs_[0]>0.1).sum(axis=1)>0\n",
    "X_train=X_train[:,filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2153L, 489L)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((classifiers[\"Neural Network\"][\"f\"].coefs_[0]>0.1).sum(axis=1)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=np.asarray(new_metric,dtype=\"float64\")\n",
    "Y=np.asarray(Y,dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import fbeta_score,make_scorer\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "    title : string. Title for the chart.\n",
    "    X : array-like, shape (n_samples, n_features).Training vector.\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional. None for unsupervised learning.\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "    n_jobs : integer, optional. Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    fone_scorer = make_scorer(fbeta_score, beta=1)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,scoring=fone_scorer)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "#title = \"Learning Curves (Naive Bayes)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "#cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "#estimator = MultinomialNB()\n",
    "#plot_learning_curve(estimator, title,X_train, y_train[:,2], ylim=(0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves (Neural Network using Logistic Neuron)\"\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.1, random_state=0)\n",
    "estimator = MLPClassifier(solver='lbfgs', activation=\"logistic\",alpha=0.001,hidden_layer_sizes=(25,), random_state=1)\n",
    "plot_learning_curve(estimator, title, X_train, y_train[:,2], (0, 1.01), cv=cv, n_jobs=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 5 elements, new values have 3 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-69229b3ee1c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mAcc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"f\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"f\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7169e0c15dd4>\u001b[0m in \u001b[0;36mScore\u001b[1;34m(PredictList, TrueList, beta)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPredictList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrueList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predict'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mAcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Predict'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mAcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\junior\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   2683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\properties.pyx\u001b[0m in \u001b[0;36mpandas.lib.AxisProperty.__set__ (pandas\\lib.c:44748)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\junior\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\junior\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m   2633\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[0;32m   2634\u001b[0m                              \u001b[1;34m'new values have %d elements'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2635\u001b[1;33m                              (old_len, new_len))\n\u001b[0m\u001b[0;32m   2636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2637\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 5 elements, new values have 3 elements"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=[\"accuracy\",\"f-beta\",\"recall\",\"precision\"])\n",
    "colors = [ 'yellow', 'blue', 'green']\n",
    "plt.figure()\n",
    "lw = 2\n",
    "\n",
    "for model,color,label in zip(classifiers,colors,labels):\n",
    "    Acc,rate,f1,recall,precision=Score(classifiers[model][\"f\"].predict(X_test),y_test,beta)\n",
    "    results.loc[i]=rate,f1,recall,precision\n",
    "    fp,tp,threshold=roc_curve(y_test,classifiers[model][\"f\"].predict_proba(X_test)[:,-1])\n",
    "    plt.plot(fp, tp, color=color,lw=lw, label=model)\n",
    "print results\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        accuracy    f-beta    recall  precision\n",
      "yellow  0.698582  0.628821  0.791209   0.521739\n",
      "blue    0.808511  0.289474  0.785714   0.177419\n",
      "local   0.900709  0.333333  0.538462   0.241379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "results = pd.DataFrame(columns=[\"accuracy\",\"f-beta\",\"recall\",\"precision\"])\n",
    "colors = [ 'yellow', 'blue', 'green']\n",
    "labels=[ 'yellow', 'blue', 'local']\n",
    "plt.figure()\n",
    "lw = 2\n",
    "for i,color,label,model in zip(range(3),colors,labels,classifiers):\n",
    "    Acc,rate,f1,recall,precision=Score(classifiers[model][\"f\"].predict(X_test),y_test[:,i],beta)\n",
    "    results.loc[label]=rate,f1,recall,precision\n",
    "    fp,tp,threshold=roc_curve(y_test[:,i],classifiers[model][\"f\"].predict_proba(X_test)[:,-1])\n",
    "    roc_auc = auc(fp, tp)\n",
    "    plt.plot(fp, tp, color=color,lw=lw, label=label+'(area = %0.2f)' % (roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k',label='Random')\n",
    "print results\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
